# RIPIS - Real-Time Interview Practice Intelligence System

## Complete Documentation

A desktop-based AI mock interview system featuring real-time voice interaction, intelligent feedback, and comprehensive mistake tracking.

---

## Table of Contents

1. [Overview](#overview)
2. [Features](#features)
3. [System Requirements](#system-requirements)
4. [Installation](#installation)
5. [Configuration](#configuration)
6. [Usage Guide](#usage-guide)
7. [Architecture](#architecture)
8. [Interview Flow](#interview-flow)
9. [API Reference](#api-reference)
10. [Troubleshooting](#troubleshooting)

---

## Overview

RIPIS (Real-Time Interview Practice Intelligence System) is an AI-powered mock interview application designed to help developers practice technical interviews. It provides a realistic interview experience with:

- **Real-time voice interaction** using Vosk speech recognition
- **AI interviewer (Alex)** powered by Ollama/Mistral
- **Syntax-highlighted code editor** for writing solutions
- **Intelligent feedback** with mistake tracking
- **Edge case follow-ups** to test understanding

---

## Features

### Core Features
| Feature | Description |
|---------|-------------|
| üéôÔ∏è **Voice Interaction** | Speak naturally with the AI interviewer using Vosk STT |
| üíª **Code Editor** | Write code with Python/Java/C++/JavaScript syntax highlighting |
| ü§ñ **AI Feedback** | Real-time feedback with [CORRECT]/[WRONG] tracking |
| üìä **Mistake Tracking** | Records wrong answers and summarizes them before moving on |
| üéØ **Edge Case Testing** | AI asks about edge cases after you complete a problem |
| üîá **Microphone Toggle** | Mute/unmute mic to prevent unwanted speech recognition |

### Interview Types Supported
- **DSA (Data Structures & Algorithms)** - Coding problems
- **System Design** - Architecture questions
- **DBMS** - Database concepts
- **Operating Systems** - OS fundamentals
- **OOP Concepts** - Object-oriented programming

---

## System Requirements

### Hardware
- Microphone (for voice input)
- Speakers (for AI voice output)
- Minimum 8GB RAM (for AI model)

### Software
- **Python 3.11+**
- **Ollama** (for LLM)
- **FFmpeg** (for audio processing)
- Windows 10/11 (tested)

---

## Installation

### Step 1: Install Python Dependencies

```bash
pip install PyQt6 PyQt6-QScintilla vosk sounddevice numpy requests pyttsx3 ollama pydub
```

### Step 2: Install and Configure Ollama

```bash
# Download Ollama from https://ollama.ai
# Then pull the Mistral model
ollama pull mistral:7b-instruct

# Start Ollama server
ollama serve
```

### Step 3: Download Vosk Model

1. Download from: https://alphacephei.com/vosk/models
2. Recommended: `vosk-model-en-us-0.22-lgraph` (better accuracy)
3. Extract to: `ripis/models/vosk-model-en-us-0.22-lgraph/`

### Step 4: Configure FFmpeg (Optional)

Update `config.py` with your FFmpeg path:
```python
FFMPEG_PATH = r"C:\path\to\ffmpeg\bin"
```

### Step 5: Run the Application

```bash
python main.py
```

---

## Configuration

### config.py Settings

```python
# Vosk Speech Recognition
VOSK_MODEL_PATH = "models/vosk-model-en-us-0.22-lgraph"
SAMPLE_RATE = 16000

# Ollama LLM
OLLAMA_MODEL = "mistral:7b-instruct"
OLLAMA_HOST = "http://127.0.0.1:11434"

# Interview Settings
INTERVIEW_TYPES = ["DSA", "System Design", "DBMS", "Operating Systems", "OOP Concepts"]
HINT_LEVELS = 3  # Progressive hint depth

# Audio Settings
AUDIO_CHUNK_SIZE = 8000
SILENCE_THRESHOLD = 1.5  # seconds
```

---

## Usage Guide

### Starting an Interview

1. **Click "Start Interview"** - AI (Alex) greets you
2. **Choose interview type** - Say "coding" or "system design"
3. **Solve the problem** - Write code and explain your approach
4. **Get feedback** - AI responds with [CORRECT]/[WRONG] tags
5. **Handle edge cases** - AI asks follow-up edge case questions
6. **Click "End Session"** - Get summary with mistakes review

### Controls

| Button | Function |
|--------|----------|
| **Start Interview** | Begin a new interview session |
| **End Session** | End interview and get feedback summary |
| **Request Hint** | Get a progressive hint (3 levels) |
| **üé§ Mic Toggle** | Mute/unmute voice input |

### Voice Commands

| Say This | What Happens |
|----------|--------------|
| "coding" / "DSA" | Select coding interview |
| "system design" | Select system design interview |
| "I'm done" / "finished" | Move to follow-up questions |
| "hint" / "help" | Request a hint |

---

## Architecture

### Project Structure

```
ripis/
‚îú‚îÄ‚îÄ main.py                    # Application entry point
‚îú‚îÄ‚îÄ config.py                  # Configuration settings
‚îú‚îÄ‚îÄ requirements.txt           # Python dependencies
‚îÇ
‚îú‚îÄ‚îÄ core/                      # Core business logic
‚îÇ   ‚îú‚îÄ‚îÄ ai_engine.py          # Ollama API integration
‚îÇ   ‚îú‚îÄ‚îÄ interview_state.py    # State machine & flow control
‚îÇ   ‚îî‚îÄ‚îÄ prompt_templates.py   # AI prompt templates
‚îÇ
‚îú‚îÄ‚îÄ audio/                     # Audio processing
‚îÇ   ‚îú‚îÄ‚îÄ speech_recognition.py # Vosk STT integration
‚îÇ   ‚îî‚îÄ‚îÄ text_to_speech.py     # pyttsx3 TTS output
‚îÇ
‚îú‚îÄ‚îÄ ui/                        # User interface
‚îÇ   ‚îú‚îÄ‚îÄ main_window.py        # Main application window
‚îÇ   ‚îú‚îÄ‚îÄ code_editor.py        # QScintilla code editor
‚îÇ   ‚îî‚îÄ‚îÄ status_panel.py       # Controls & transcript
‚îÇ
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ questions/            # Question bank (JSON)
‚îÇ
‚îú‚îÄ‚îÄ models/                    # ML models
‚îÇ   ‚îú‚îÄ‚îÄ vosk-model-*/         # Vosk speech models
‚îÇ   ‚îî‚îÄ‚îÄ Piper/                # TTS models (optional)
‚îÇ
‚îî‚îÄ‚îÄ utils/                     # Utility functions
```

### Component Diagram

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Main Window                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Code Editor    ‚îÇ  ‚îÇ       Status Panel              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (QScintilla)    ‚îÇ  ‚îÇ  - Transcript                   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ  - Controls                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ  ‚îÇ  - Mic Toggle                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ                        ‚îÇ
              ‚ñº                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Interview Worker   ‚îÇ    ‚îÇ  Speech Recognition  ‚îÇ
‚îÇ     (QThread)        ‚îÇ    ‚îÇ      (Vosk)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Interview State Machine             ‚îÇ
‚îÇ  States: IDLE ‚Üí GREETING ‚Üí SOLVING ‚Üí CLOSING    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ
              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ      AI Engine       ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Text-to-Speech     ‚îÇ
‚îÇ    (Ollama API)      ‚îÇ    ‚îÇ     (pyttsx3)        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Interview Flow

### State Machine

```
IDLE ‚Üí GREETING ‚Üí TOPIC_SELECTION ‚Üí QUESTION_PRESENTING ‚Üí CANDIDATE_SOLVING
                                                              ‚îÇ
                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                    ‚ñº                         ‚ñº
                              GIVING_HINT              FOLLOW_UP
                                    ‚îÇ                         ‚îÇ
                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                                                              ‚ñº
                                                          CLOSING ‚Üí ENDED
```

### Interview Logic

1. **Greeting Phase**
   - AI introduces itself
   - Asks for interview type preference

2. **Question Phase**
   - AI generates a problem based on type/difficulty
   - Displays in code editor
   - Speaks the problem explanation

3. **Solving Phase** (5 attempts max)
   - Listens to candidate responses
   - Provides feedback with [CORRECT]/[WRONG]/[UNCLEAR] tags
   - Records mistakes for later review
   - Filters garbage/noise input

4. **Follow-up Phase**
   - Asks edge case questions
   - Tests understanding of solution

5. **Transition Phase**
   - Gives feedback on mistakes from current question
   - Moves to next question OR concludes

6. **Closing Phase**
   - Summarizes all questions covered
   - Lists mistakes with corrections
   - Provides improvement suggestions

---

## API Reference

### AIEngine

```python
class AIEngine:
    def generate_response(prompt: str) -> str
        """Generate AI response using Ollama."""
    
    def reset_conversation() -> None
        """Clear conversation history."""
```

### InterviewStateMachine

```python
class InterviewStateMachine:
    def start_interview() -> str
        """Start new interview, returns greeting."""
    
    def process_user_input(text: str) -> str
        """Process user speech, returns AI response."""
    
    def end_interview() -> str
        """End interview, returns closing summary."""
    
    def request_hint() -> str
        """Get progressive hint (levels 1-3)."""
```

### InterviewContext

```python
@dataclass
class InterviewContext:
    interview_type: str      # DSA, System Design, etc.
    difficulty: str          # easy, medium, hard
    current_question: str    # Active problem
    current_code: str        # User's code
    hints_given: int         # Hint count (0-3)
    mistakes: list           # [{question, wrong_answer, correction}]
    follow_up_attempts: int  # Retry counter
    max_retries: int = 5     # Max attempts before moving on
```

---

## Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **"Ollama not running"** | Run `ollama serve` in terminal |
| **"Vosk model not found"** | Download model from alphacephei.com/vosk/models |
| **"No audio output"** | Check Windows speaker settings |
| **"FFmpeg not found"** | Update `FFMPEG_PATH` in config.py |
| **AI gives empty responses** | Increase API timeout in ai_engine.py |
| **Speech recognition garbled** | Use larger Vosk model (lgraph version) |

### Debug Logging

The application logs extensively. Watch for these prefixes:

- `[Speech RAW]` - Raw speech recognition output
- `[Speech FINAL]` - Cleaned speech text
- `[AI]` - AI engine requests/responses
- `[State]` - Interview state changes
- `[Worker]` - Background thread activity

### Performance Tips

1. **Use larger Vosk model** for better accuracy
2. **Reduce background noise** for cleaner speech input
3. **Speak clearly and at normal pace**
4. **Keep Ollama running** before starting app

---

## Ethical Notice

This tool is designed for **practice and learning only**:

- ‚úÖ AI assistance is always visible and disclosed
- ‚úÖ Intended for self-improvement and practice
- ‚ùå NOT intended for actual interviews or assessments
- ‚ùå NOT for cheating in real interview scenarios

---

